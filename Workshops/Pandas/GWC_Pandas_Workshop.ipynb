{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Girls Who Code - Python Series\n",
    "## Pandas\n",
    "## Mentor - Amir ElTabakh\n",
    "\n",
    "Pandas is a Python library used for data manipulation and analysis. It's name is a play on \"Python Data Analysis\", and was published as an open source library in 2009 by Wes McKinney. \n",
    "\n",
    "#### Agenda\n",
    "- Installing Python packages on your machine\n",
    "- Data Exploration\n",
    "- Data Cleaning\n",
    "- Data Visualizations\n",
    "\n",
    "Pandas does not come with the standard Python library, as Python is open source and developers are creating new libraries all the time. To install Pandas on our machine we will pip install it. pip is the standard package manager for Python, it allows you to install and manage additional packages. The Python installer installs pip, so it should be ready for use. Verify that pip is installed by running the following command"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip --version"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's pip install pandas with the following command. Note when using a Notebook, such as this one on Jupyter, we can run shell commands by starting a line with an exclamation mark."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install pandas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we've installed Pandas, lets import the library. Note that we only have to install a library once per machine, but we have to import it in every program we wish to use the library in."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pandas is the most common library for data analytics, and data wrangling. Thankfully theres a lot of documentation.\n",
    "\n",
    "https://pandas.pydata.org/pandas-docs/stable/user_guide/index.html#user-guide\n",
    "\n",
    "\n",
    "Excel files are commonly saved as either a `.csv` or `.xlsx` files. CSV stands for Comma Seperated Values, its a plain text file that contains a list of data. XLSX files are files used in Microsoft Excel, a spreadsheet application that uses tables to organize, analyze, and store data. Microsoft Excel encourages saving your file as an `.xlsx` file.\n",
    "\n",
    "We will be importing CSV files in our workshop, the code to import a CSV file is different from the code to import an XLSX file. To import an XLSX file run this code.\n",
    "\n",
    "`variable_name = pd.read_excel(\"Resources/file_name.xlsx\", sheet_name=\"optional\")`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing CSVs\n",
    "school_data_df = pd.read_csv(\"Resources/schools_complete.csv\")\n",
    "student_data_df = pd.read_csv(\"Resources/students_complete.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "school_data_df.head(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "student_data_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "student_data_df[[\"reading_score\", \"math_score\"]].describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.describe.html?highlight=describe#pandas.DataFrame.describe\n",
    "\n",
    "This is the documentation for the describe method.\n",
    "```\n",
    "Descriptive statistics include those that summarize the central tendency, dispersion and shape of a datasetâ€™s distribution, excluding NaN values.\n",
    "```\n",
    "We've gotten a high level overview of the reading and the math scores, but what is the average of the two scores?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reading_score_mean = student_data_df[\"reading_score\"].mean()\n",
    "math_score_mean = student_data_df[\"math_score\"].mean()\n",
    "total_mean = (reading_score_mean + math_score_mean) / 2\n",
    "\n",
    "print(f\"Reading Score Mean: {round(reading_score_mean, 2)}\")\n",
    "print(f\"Math Score Mean: {round(math_score_mean, 2)}\")\n",
    "print(f\"Average Score: {round(total_mean, 2)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Cleaning\n",
    "### Checking for missing data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets take a look at the first 5 rows of each dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To get the total number of empty rows, or rows that are \"True\", we can use the Pandas \".sum()\" method\n",
    "# after the \".isnull()\" method.\n",
    "student_data_df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "student_data_df.notnull()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Thankfully there are no null values in our student_df dataframe, so that saves us some time. There are multiple approaches to dealing with missing data. Lets import a dataset and practice how we would deal with missing data.\n",
    "\n",
    "Consider if have missing data points in the `reading_score` and the `math_score` columns. If we do nothing, when we sum or take the averages of the reading and math scores, those NaNs will not be considered. However if we multiply or divide with a row that has a NaN, the answer will be NaN. This may cause problems.\n",
    "\n",
    "There are two simple approaches to dealing with the missing data.\n",
    "\n",
    "- Drop the rows where there are NaNs. This can cause problems later if there is data in the other rows that we need. Before dropping rows with NaN, you should ask yourself how much data would be removed if NaNs are dropped, and how it would impact analysis.\n",
    "```\n",
    "# Drop the NaNs\n",
    "missing_grade_df.dropna()\n",
    "```\n",
    "- We can choose to fill in the row. Filling in an empty row must be used with caution, adding irrelevant data may impact arithmetic calculations.\n",
    "```\n",
    "# Fill in the empty rows with 85.\n",
    "missing_grade_df.fillna(85)\n",
    "```\n",
    "There are so many ways to deal with missing data, find one that works for your needs."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cleaning Student Names\n",
    "\n",
    "Some names have prefixes. Row 4 has a student with the prefix 'Dr.'. Lets remove all of the prefixes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Outputting the column vector `student_name`.\n",
    "student_data_df[\"student_name\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "student_names = student_data_df[\"student_name\"].tolist()\n",
    "student_names[0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter this list using a conditional statement. If the length of the name\n",
    "# is greater than 2, we append it to a new list\n",
    "students_to_fix = []\n",
    "\n",
    "for name in student_names:\n",
    "    if len(name.split()) > 2:\n",
    "        students_to_fix.append(name)\n",
    "\n",
    "print(\"There are \" + str(len(students_to_fix)) + \" invalid names out of a total \" + str(len(student_names)) + \".\")\n",
    "students_to_fix[0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Add the prefixes less than or equal to 4 to a new list\n",
    "prefixes = []\n",
    "\n",
    "for name in students_to_fix:\n",
    "    if len(name.split()[0]) <= 4:\n",
    "        prefixes.append(name.split()[0])\n",
    "        \n",
    "print(pd.Series(prefixes).unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prefixes = ['Dr.', 'Mr.', 'Mrs.', 'Miss', 'Ms.']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add the suffixes less than or equal to 3 to a new list\n",
    "suffixes = []\n",
    "\n",
    "for name in students_to_fix:\n",
    "    if len(name.split()[-1]) <= 3:\n",
    "        suffixes.append(name.split()[-1])\n",
    "        \n",
    "print(pd.Series(suffixes).unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "suffixes = ['MD', 'III', 'DVM', 'DDS', 'II', 'PhD', 'Jr.', 'IV']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add each prefix and suffix to remove to a list.\n",
    "prefixes_suffixes = prefixes + suffixes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Iterate through the \"prefixes_suffixes\" list and replace them with an empty space, \"\" when it appears in the student's name\n",
    "\n",
    "for word in prefixes_suffixes:\n",
    "    student_data_df[\"student_name\"] = student_data_df[\"student_name\"].str.replace(word,\"\")\n",
    "    \n",
    "# Put the cleaned student's names in another list\n",
    "student_names = student_data_df[\"student_name\"].tolist()\n",
    "student_names[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Practice Reading Documentation\n",
    "\n",
    "Use the [Pandas Documentation](https://pandas.pydata.org/pandas-docs/stable/user_guide/index.html) to answer the following questions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# What school in `school_data_df` has the highest budget\n",
    "# ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# What is the total sum of the budgets of all schools in `school_data_df`\n",
    "# ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# What school has the greatest average reading score\n",
    "# ...\n",
    "\n",
    "# What school has the lowest average math score\n",
    "# ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# What is the proportion of Males to Females according to `student_data_df`\n",
    "# ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# What are the mean scores per school?\n",
    "# ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# What are the mean scores per grade?\n",
    "# ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Visualization\n",
    "\n",
    "\n",
    "### Histogram\n",
    "The histogram shows the distribution of a continuous variable. It can discover the frequency distribution for a single variable in a univariate analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing dependencies\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Histogram of Reading Scores in the District\n",
    "plt.hist(student_data_df['reading_score'])\n",
    "plt.title(\"Histogram of Reading Scores\")\n",
    "plt.xlabel(\"Score\")\n",
    "plt.ylabel(\"Frequency\")\n",
    "plt.show() # This displays the graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Histogram of Reading Scores in the District\n",
    "plt.hist(student_data_df['reading_score'], bins = 30)\n",
    "plt.title(\"Histogram of Reading Scores\")\n",
    "plt.xlabel(\"Score\")\n",
    "plt.ylabel(\"Frequency\")\n",
    "plt.show() # This displays the graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Barplot of Budgets in the District\n",
    "school_name_list = school_data_df['school_name'].tolist()\n",
    "school_budget_list = school_data_df['budget'].tolist()\n",
    "\n",
    "sns.barplot(school_budget_list, school_name_list)\n",
    "plt.title(\"Barplot of School Budgets\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "school_data_df['type'].value_counts()[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a Pie Chart of the 'District'/'Charter' distribution\n",
    "school_data_df['type'].value_counts()\n",
    "\n",
    "charter_count = school_data_df['type'].value_counts()[0]\n",
    "district_count = school_data_df['type'].value_counts()[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = ['Charter', 'District']\n",
    "sizes = [charter_count, district_count]\n",
    "colors = ('cyan', 'coral')\n",
    "explode = (0.1, 0)\n",
    "\n",
    "# Creating plot\n",
    "fig = plt.figure(figsize =(10, 7))\n",
    "plt.pie(x = sizes, labels = labels, colors = colors, explode = explode, autopct='%1.1f%%', shadow=True, startangle=140)\n",
    "plt.title(\"Pie Chart of 'District'/'Charter' Distribution\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Histogram of Math Scores in the District\n",
    "plt.hist(student_data_df['math_score'], bins = 20)\n",
    "plt.title(\"Histogram of Math Scores\")\n",
    "plt.xlabel(\"Score\")\n",
    "plt.ylabel(\"Frequency\")\n",
    "plt.show() # This displays the graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a Pie Chart of the 'M'/'F' distribution\n",
    "student_data_df['gender'].value_counts()\n",
    "\n",
    "M_count = student_data_df['gender'].value_counts()[0]\n",
    "F_count = student_data_df['gender'].value_counts()[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pie Chart of 'M'/'F' distribution\n",
    "\n",
    "labels = ['M', 'F']\n",
    "sizes = [M_count, F_count]\n",
    "colors = ('cyan', 'indigo')\n",
    "\n",
    "# Creating plot\n",
    "fig = plt.figure(figsize =(10, 7))\n",
    "plt.pie(x = sizes, labels = labels, colors = colors, autopct='%1.1f%%')\n",
    "plt.title(\"Pie Chart of M/F Distribution\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
